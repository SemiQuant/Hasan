```{r setup, include=FALSE, echo=TRUE}
<<<<<<< HEAD
require(DT)
require(visNetwork)
require(igraph)
require(stringr)
require(tidyverse)
require(reticulate)
reticulate::use_condaenv("hasan", required = TRUE)
```

<!-- #TODO -->

<!-- add if input file has G,A that these are then separated -->

<!-- need to sort the input file by chrom then position -->

<!-- need to mask all calls that arent reference or alt for each read, as we not calling mutations here but rather haploypes -->

<!-- can this deal with indels properly yet? -->

<!-- Fix the fact that you have to add the reference to the input, but I suppose this is fine as you only want to look at those mutations, and what if the reference isnt part of them? -->

```{r inputs, include=FALSE, echo=FALSE}
# bam <- "/Users/SemiQuant/Bioinformatics/Projects/Hasan/test/test2/test_pairedBWA_sorted.bam"
# snps <- "/Users/SemiQuant/Bioinformatics/Projects/Hasan/test/test2/snps.tsv"
source("inputs.R")
```

```{python phase mutations, include=FALSE, echo=FALSE}
=======
require(reticulate)
reticulate::use_condaenv("hasan", required = TRUE)


```

<!-- #TODO -->
<!-- add if input file has G,A that these are then separated -->
<!-- need to sort the input file by chrom then position -->
<!-- need to mask all calls that arent reference or alt for each read, as we not calling mutations here but rather haploypes -->
<!-- can this deal with indels properly yet? -->
 <!-- Fix the fact that you have to add the reference to the input, but I suppose this is fine as you only want to look at those mutations, and what if the reference isnt part of them? -->

```{python phase mutations, include=FALSE}
>>>>>>> b13ec9d4377a6b6ebf618a05233babaf93230f71
import pysam
from collections import Counter
import pandas as pd
# samfile = pysam.AlignmentFile("/Users/SemiQuant/Downloads/BDQ_haplo/TB-B240-054_S26-bowtie2.bam", "rb")
<<<<<<< HEAD
samfile = pysam.AlignmentFile(r.bam, "rb")
=======
samfile = pysam.AlignmentFile("/Users/SemiQuant/Bioinformatics/Projects/Hasan/test/test2/test_pairedBWA_sorted.bam", "rb")
>>>>>>> b13ec9d4377a6b6ebf618a05233babaf93230f71

# var_dic will be snps/indels, if also adding reference then edit the below
# import numpy as np
# vant = np.loadtxt("/Users/SemiQuant/Bioinformatics/Projects/Hasan/snps.tsv", delimiter="\t", 
#           dtype={'names': ('CHROM', 'POS', 'REF', 'ALT', 'TYPE'),
#           'formats': ('<U100', 'int', 'U10', 'U10', 'U10')}, skiprows=1)
var_dic = {}
# this is gross, but i dont really speak python 
# with open("/Users/SemiQuant/Bioinformatics/Projects/Hasan/snps.tsv") as f:
<<<<<<< HEAD
with open(r.snps) as f:
=======
with open("/Users/SemiQuant/Bioinformatics/Projects/Hasan/test/test2/snps.tsv") as f:
>>>>>>> b13ec9d4377a6b6ebf618a05233babaf93230f71
    next(f) # skip header line
    for line in f:
        (CHROM, POS, REF, ALT, TYPE) = line.split()
        try:
            var_dic[CHROM][int(POS)].setdefault('call', []).append(ALT)
        except:
            try:
                var_dic[CHROM][int(POS)] = {'call' : [ALT]}
            except:
                var_dic[CHROM] = {int(POS) : {'call' : [ALT]}}

# var_dic={'rpoC': {1221: {'call': ['T']}}, 'Rv0678_amplicon4': {111: {'call': ['A', 'G', 'G', 'T']}, 112: {'call': ['G', '-']}, 114: {'call': ['C']}, 116: {'call': ['C']}}}var_dic={'rpoC': {1221: {'call': ['T']}}, 'Rv0678_amplicon4': {111: {'call': ['A', 'G', 'G', 'T']}, 112: {'call': ['G', '-']}, 114: {'call': ['C']}, 116: {'call': ['C']}}}

# this is like this as I dont really know pysam and how to do it cleaner, with also getting readnames
for chrom in var_dic:
    if chrom not in samfile.references:
        print(chrom, " not found in bam file!")
    else:
        for i in var_dic[chrom]:
            for pileupcolumn in samfile.pileup(chrom, i, i+1):
                for pileupread in pileupcolumn.pileups:
                    try:
                        if pileupread.alignment.get_reference_positions()[pileupread.query_position] == i:
                        # if pileupread.query_position == i:
                            if not pileupread.is_del: # if reference then add
                                read_call_tmp = pileupread.alignment.query_sequence[pileupread.query_position]
                                try:
                                    #  check if it matches the call in there as pairs have same name
                                    if read_call_tmp == var_dic[chrom][i][pileupread.alignment.query_name]:
                                        break
                                    else:
                                        var_dic[chrom][i][pileupread.alignment.query_name] = "N"
                                except:
                                    if read_call_tmp in var_dic[chrom][i]["call"]:
                                        var_dic[chrom][i][pileupread.alignment.query_name] = read_call_tmp
                                    else:
                                        var_dic[chrom][i][pileupread.alignment.query_name] = "N"
                                # elif not pileupread.is_refskip: #if reference then add, not sure if this is working, it isnt so adding the reference to the dic?
                                #         var_dic[chrom][i][pileupread.alignment.query_name] = read_call_tmp
                            else:
                                try:
                                    #  check if it matches the call in there as pairs have same name
                                    if read_call_tmp == var_dic[chrom][i][pileupread.alignment.query_name]:
                                        break
                                    else:
                                        var_dic[chrom][i][pileupread.alignment.query_name] = "N"
                                except:
                                    if read_call_tmp == var_dic[chrom][i][pileupread.alignment.query_name]:
                                        break
                                    else:
                                        var_dic[chrom][i][pileupread.alignment.query_name] = "-"
                    except:
                        pass

# var_df = pd.DataFrame.from_dict(var_dic)
# var_df.reset_index(drop=True, inplace=True)
# var_df = var_df[1:]
var_df = pd.DataFrame.from_dict({(i,j): var_dic[i][j] 
                           for i in var_dic.keys() 
                           for j in var_dic[i].keys()},
                       orient='columns')
var_df.columns = var_df.columns.to_flat_index()
# var_df.columns = [' '.join(str(col)).strip() for col in var_df.columns.values]
var_df = var_df[1:]

# make this happen in the above rather
cnms = []
for col in var_df.columns.values:
    cnms.append(col[0] + "_" + str(col[1]))

var_df.columns = cnms
# var_df.to_pickle("/Users/semiquant/Bioinformatics/Projects/Hasan/test/var_df.pkl")
```

<<<<<<< HEAD
<!-- ```{python phase mutations savefile, include=FALSE} -->

<!-- import pandas as pd -->

<!-- var_df = pd.read_pickle("/Users/semiquant/Bioinformatics/Projects/Hasan/test/var_df.pkl") -->

<!-- ``` -->

```{r import and style matrix, echo=FALSE}
# require(stringr)
# require(tidyverse)
=======

```{python phase mutations savefile, include=FALSE}
import pandas as pd

var_df = pd.read_pickle("/Users/semiquant/Bioinformatics/Projects/Hasan/test/var_df.pkl")
```


```{r import and style matrix}
require(stringr)
require(tidyverse)
>>>>>>> b13ec9d4377a6b6ebf618a05233babaf93230f71
phase_out <- py$var_df
phase_out[phase_out == "NaN"] <- "N"
phase_out <- phase_out %>% 
  group_by_all() %>% 
  summarise(Count = n())
phase_out <- phase_out %>% unite("Seq", -Count, remove = F, sep = '')

# remove rows with only Ns
phase_out <- phase_out[grepl("[agctAGCT]", phase_out$Seq), ]
```

<<<<<<< HEAD
```{r get haplos, echo=FALSE}
# require(DT)
=======

```{r get haplos}
require(DT)
>>>>>>> b13ec9d4377a6b6ebf618a05233babaf93230f71
# phase_out <- tibble::tribble(
#   ~Seq, ~rv0678_500_489, ~rv0678_500_874, ~rv0678_500_875, ~Count,
#   "ANC",             "A",             "N",             "N",  7931L,
#   "CNT",             "C",             "C",             "T",   400L,
#   "ACN",             "A",             "C",             "T",   131L,
#   "ATN",             "A",             "T",             "T",  3329L,
#   "CTT",             "C",             "T",             "T",   343L
# )


<<<<<<< HEAD
# require(igraph)
=======
require(igraph)
>>>>>>> b13ec9d4377a6b6ebf618a05233babaf93230f71
phase_tmp <- phase_out

# TODO
# for now, remove those with gaps in the middle
# phase_tmp <- phase_tmp[!grepl("[AGCT-]N[AGCT-]", phase_tmp$Seq),]
# phase_tmp <- phase_tmp[phase_tmp$Seq!="NNNN",]


dat <- phase_tmp[-c(1)]
dat <- apply(dat, 2, function(x) as.character(x))
dat[dat == "N"] <- NA
# remove only NA columns
dat <- dat[,apply(dat, 2, function(x) sum(is.na(x))) < nrow(dat)]
dat <- as_tibble(dat)


# add start position
# dat$strt <- ifelse(is.na(unlist(dat[,1])), NA, "Y")
dat$strt <- "Y"

dat <- dat %>% 
  select(Count, strt, everything()) %>% 
  mutate(Count = as.numeric(Count))



freq <- data.frame(dat[c(1)])
for (c in 2:ncol(dat)){
  d <- dat[,c(1, c)]
  d.sum <- sum(d[complete.cases(d),]$Count)
  d$Count[is.na(d[c(2)])] <- 0
  d <- d$Count/d.sum
  freq <- cbind(freq, d)
}
colnames(freq) <- colnames(dat)




# if NA before or after then skip, else, add _row
# LOOOOL, look at this monstrocity, be less of a cunt bro
for (r in 1:nrow(dat)){
  for (c in 3:ncol(dat)){
    if (c == ncol(dat)){
      if (!is.na(dat[r, c])){
        dat[r, c] <- paste0(dat[r, c], "_", r)
      }
    }else{
      if (!is.na(dat[r, c])){
        if (is.na(dat[r, c-1]) | is.na(dat[r, c+1])){
          #arg
        }else{
          dat[r, c] <- paste0(dat[r, c], "_", r)
        }
      }
    }
  }
}



for (c in 3:ncol(dat)){
  dat[,c] <- paste0(unlist(dat[,c]), "_", gsub(".*_", "", colnames(dat)[c]))
}
for (r in 1:nrow(dat)){
  dat[r,][grepl("NA_", dat[r,])] <- NA
}


for (c in 3:ncol(freq)){
  freq[,c] <- ifelse(freq[,c] == 0, freq[,c-1], freq[,c])
}




# if an na, make all possible
# change to apply, dont this way first for ease



while(sum(is.na(dat))>0){
  for (r in 1:nrow(dat)){
    for (cl in 3:ncol(dat)){
      if (is.na(dat[r,cl])){
        tmp <- dat[r,cl]
        pos <- paste0(unlist(na.omit(dat[,cl])) %>% strtrim(1) %>% unique(),
                      "_", gsub(".*_", "", colnames(dat[,cl])))
        tmp <- do.call("rbind", replicate(length(pos), dat[r,], simplify = FALSE))
        tmp[,cl] <- pos
        tmp.freq <- do.call("rbind", replicate(length(pos), freq[r,], simplify = FALSE))
        # tmp.freq[,cl] <- tmp.freq[,cl]/nrow(pos)
        tmp.freq <- tmp.freq/length(pos)
        dat <- dat[-r,]
        freq <- freq[-r,]
        dat <- rbind(dat, tmp)
        freq <- rbind(freq, tmp.freq)
        
      }
    }
  }
}






















test <- NULL
for (c in seq(ncol(dat)-1)){
  if (c>1){
    test.tmp <- dat[,c(1, c, c+1)]
    test.tmp$Count <- unlist(freq[c])
    colnames(test.tmp) <- c("weight", "from", "to")
    test <- rbind(test, test.tmp)
  }
}

# 
# test <- test[!(is.na(test$from)),] #test <- test[complete.cases(test),]
# 
# 
# # if there is a from to a NA, and that from also occurs to a non NA to, then add an equal portion to those occurrences
# # TODO
# # i don't think this should be an equal proportion, come fix
# tmp.join <- test[is.na(test$to), ]
# for (i in unique(tmp.join$from)){
#   # i=unique(tmp.join$from)[1]
#   if (sum(i==test$to, na.rm = T) == 1){
#     # print(i)
#     # print(sum(test[test$from == i, "weight"]))
#     test[test$from == i, "weight"] <- sum(test[test$from == i, "weight"])
#   }
# }
# # tmp.join <- tmp.join[tmp.join$from%in%test$to,]
# # tmp.join
# 
# 
# test <- test[complete.cases(test),]



# add  first, Y, and final, Z connection
all_nodes <- unique(c(test$from, test$to))
missing_conn_out <- data.frame()

# add in missing connections
missing_conn <- all_nodes[!all_nodes%in%test$from]





for (node in missing_conn){
  pos <- as.integer(tail(str_split(node, "_")[[1]], 1))
  if (pos == as.integer(gsub(".*_", "", colnames(dat)[ncol(dat)]))){
    nxt_pos <- "Z"
  }else{
    nxt_pos <- all_nodes[grepl(paste0("_", pos+1, "$"), all_nodes)]
  }
  for (to in nxt_pos){
    if (length(nxt_pos)==1){
      missing_conn_out <- rbind(missing_conn_out, 
                                c(1, node, to))
    }else{
      # get the sum of the connections from the next node
      to_weight <- sum(test[grepl(paste0(to, "$"), test$from), "weight"])
      missing_conn_out <- rbind(missing_conn_out, 
                                c(to_weight, node, to))
    }
  }
}




##############################################################################################################
# TODO
# PROBLEM HAPPENDS IF THERE IS NO POSSIBLILTY FOR A SEQUENCE, I.E., THERE ARE NO SEQS THAT END BEFORE IT STARTS

missing_conn_in <- all_nodes[!all_nodes%in%test$to]
missing_conn_in <- missing_conn_in[!grepl("^Y$", missing_conn_in)]
# gsub(".*_", "", missing_conn_in)
for (node in missing_conn_in){
  missing_conn_out <- rbind(missing_conn_out, 
                            c(1, "Y", node))
}



##############################################################################################################



colnames(missing_conn_out) <- colnames(test)
missing_conn_out$weight <- as.numeric(missing_conn_out$weight)
test <- rbind(test,
              missing_conn_out)


test <- test %>% 
  group_by(from) %>% 
  mutate(weight = ifelse(weight>=1, weight/sum(weight), weight))




test$from[grepl("^Y", test$from)] <- "Y_0"




g <- graph_from_edgelist(as.matrix(test[-c(1)]), directed = T) %>% 
  set_edge_attr("weight", value = test$weight)


# plot(g)
<<<<<<< HEAD
# require(visNetwork)
=======
require(visNetwork)
>>>>>>> b13ec9d4377a6b6ebf618a05233babaf93230f71
data <- toVisNetworkData(g)
data$edges$label <- round(data$edges$weight, 3)
data$edges$value <- data$edges$weight*5
data$nodes$color.highlight.border <- "red"
n <- visNetwork(nodes = data$nodes, edges = data$edges) %>%
  visEdges(arrows = "to") %>% 
  visPhysics(enabled = F)
n %>% 
  visInteraction(multiselect=T, selectable=T) %>% 
  visOptions(selectedBy = list(
    variable = "label",
    style = "width:500px",
    multiple = TRUE, sort = FALSE
  ))




# I think this will act to reweight those tht cross over to the min
test.tmp <- test
test.tmp$capacity <- test.tmp$weight
g.tmp <- g
E(g.tmp)$capacity <- as.integer(E(g.tmp)$weight*1000)
mf <- max_flow(g.tmp, source = "Y_0", target = "Z")
E(g)$weight <- mf$flow/1000
# test.tmp$capacity=E(g)$weight





# this is basically ba slightly edited, bad version of the max flow algorithm
run <- 0
out_paths <- out_min_weight <- list()
out_remainder <- NULL
delete_this <- NULL
delete_this_too <- g








max_algo=2

# max_algo=1
# # take the mac flow and iterate down
# max_algo=2
# take the path with the smallest node and find the best path that goes through that node (does not account for ties)


# intermediate_gs <- list()
all_paths <- all_simple_paths(g, from = "Y_0", to = "Z")

if (max_algo == 1){
  while (run <= length(all_paths)){
    g.tmp <- g
    # make largest smallest
    E(g.tmp)$weight <- 1/(E(g.tmp)$weight) #/max(E(g)$weight))
    p <- shortest_paths(g.tmp, from = "Y_0", to = "Z", mode = "out")$vpath[[1]]
    p.weights <- E(g, path = p)$weight
    # n.nodes <- length(p.weights)
    p.weights <- p.weights #[-n.nodes]
    if (!any(p.weights<=0)){
      out_paths <- out_paths %>% 
        append(list(names(p)))
      out_min_weight <- out_min_weight %>% 
        append(min(p.weights))
      
      
      p.weights.delete <- E(delete_this_too, path = p)$weight
      delete_this <- c(delete_this,
                       prod((p.weights.delete/14))
      )
      
      # update weights
      E(g, path = p)$weight <- p.weights-min(p.weights)
      E(g, path = p)$weight <- ifelse(E(g, path = p)$weight < 0, 0, E(g, path = p)$weight)
      # print(E(g, path = p)$weight)
      
      # intermediate_gs <- intermediate_gs %>% 
      #   append(g)
      
    }else{
      run <- run + 1
    }
  }}else if (max_algo == 2){
    while (run <= length(all_paths)){
      all_paths <- all_simple_paths(g.tmp, from = "Y_0", to = "Z")
      # sorting like this will ensure that the path selected is that with the best route, however, neither this or the which.min(all_paths_weight) accounts for ties
      all_paths_cost <- lapply(all_paths, function(p) 
        sum(E(g.tmp, path = p)$weight))
      # sorting like this will ensure that the path selected is that with the best route, however, neither this or the which.min(all_paths_weight) accounts for ties
      all_paths <- all_paths[order(unlist(all_paths_cost), decreasing = F)]
      
      all_paths_weight <- lapply(all_paths, function(p) ifelse(
        min(E(g.tmp, path = p)$weight)>0,
        sum(E(g.tmp, path = p)$weight-min(E(g.tmp, path = p)$weight)),
        NA
      ))
      if (all(is.na(all_paths_weight))){
        break
      }else{
        p <- all_paths[[which.min(all_paths_weight)]]
        p.weights <- E(g.tmp, path = p)$weight
        
        out_paths <- append(out_paths, list(names(p)))
        out_min_weight <- append(out_min_weight, min(p.weights))
        
        # update weights
        E(g.tmp, path = p)$weight <- p.weights-min(p.weights)
        
        run <- run + 1
      }
    }
  }






out_remainder <- g

# for (i in 1:length(out_paths)){
#   out_paths[[i]] <- names(out_paths[[i]])
# }
df_out <- cbind(freq = unlist(out_min_weight), 
                # delete_this = delete_this,
                do.call(rbind.data.frame, out_paths))
df_out$freq <- round(df_out$freq/sum(df_out$freq), 3)


# TODO
# this is a quick fox for the broken code in the TODO above
for (col in ncol(df_out):3){
  df_out[,col] <- ifelse(rowSums(df_out[,col:2] == "Z") == 1, "N", df_out[,col])
}
df_out[ncol(df_out)] <- "Z"




df_out$seq <- apply(df_out[,3:(ncol(df_out)-1)], 2, function(x) gsub("_.*", "", x)) %>% 
  as.data.frame() %>% 
  unite("Seq", sep = "")

df_out <- apply(df_out, 2, function(x) gsub(".*_", "", x))


df_out <- df_out %>% 
  as_tibble() %>% 
  group_by(across(-c(1))) %>% 
  mutate(freq = sum(as.numeric(freq))) %>% 
  unique()


DT::datatable(df_out)


if (max_algo==1){
  data2 <- toVisNetworkData(g)
}else{
  data2 <- toVisNetworkData(g.tmp)
}
<<<<<<< HEAD



data2$edges$label <- round(data2$edges$weight, 3)
data2$edges$value <- data2$edges$weight*5
data2$nodes$color.highlight.border <- "red"



data2$nodes <- data2$nodes[data2$nodes$id != "Y_0",]
data2$edges <- data2$edges[data2$edges$from != "Y_0", ]


data2$nodes$label <- gsub("_.*", "", data2$nodes$label)
data2$nodes$color <- adegenet::fac2col(data2$nodes$label)

data2$edges$label <- data2$edges$title <- as.character(gsub("_.*", "", data2$edges$label))


visNetwork(nodes = data2$nodes, edges = data2$edges) %>%
  visEdges(arrows = "to") %>%
  visPhysics(enabled = F) %>% 
  visInteraction(multiselect=T, selectable=T) %>% 
  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %>% 
  visHierarchicalLayout(sortMethod = "directed", direction = "LR")





=======
data2$edges$label <- round(data2$edges$weight, 3)
data2$edges$value <- data2$edges$weight*5
data2$nodes$color.highlight.border <- "red"
n2 <- visNetwork(nodes = data2$nodes, edges = data2$edges) %>%
  visEdges(arrows = "to") %>% 
  visPhysics(enabled = F) %>% 
  visInteraction(multiselect=T, selectable=T)

n2
>>>>>>> b13ec9d4377a6b6ebf618a05233babaf93230f71



```
<<<<<<< HEAD
=======

>>>>>>> b13ec9d4377a6b6ebf618a05233babaf93230f71
